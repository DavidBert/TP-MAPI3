{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP2_MAPI3_Sujet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "m-rfarF15CUN"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidBert/TP-MAPI3/blob/master/TP2_MAPI3_Sujet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kmzmYT0H9NO",
        "colab_type": "text"
      },
      "source": [
        "# Classification avec Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8rqY3lgIV4U",
        "colab_type": "text"
      },
      "source": [
        "Nous allons dans ce TP réaliser des classifications d'images à l'aide de la librairie Keras.  \n",
        "Keras est une API de réseaux de neurones de haut niveau. Elle joue le rôle d'interface avec des librairies de deep learnning telles que TensorFlow, CNTK ou Theano. Elle est aujourd'hui totalement intégrée dans les versions actuelles de TensorFlow et permet de prototyper et d'entrainer des réseaux de neurones de façon rapide et facile tout en béneficiant des fonctionnalités offertes par TensorFlow. \n",
        "![](https://lesdieuxducode.com/images/blog/titleimages/keras-tensorflow-logo.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru9Gs7gRppAF",
        "colab_type": "text"
      },
      "source": [
        "# Multilayer-Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFGxniAPmpiB",
        "colab_type": "text"
      },
      "source": [
        "Pour commencer ce TP nous allons apprendre à utiliser Keras sur le même exemple que le TP précédent: la reconnaissance de chiffres manuscrits.  \n",
        "Nous allons donc construire un premier réseau \"fully-connected\" qui prendra en entrée une image et retournera une classification\n",
        "![](https://img.favpng.com/13/22/3/mnist-database-multilayer-perceptron-artificial-neural-network-statistical-classification-machine-learning-png-favpng-tDc3Ze2RegCutriyH12TfquqE.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1mltwf7LlDB",
        "colab_type": "text"
      },
      "source": [
        "Commençons par importer le datsset.  \n",
        "Le dataset MNIST de classification de chiffres manuscrits est déjà intégré dans la libraries Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ0cokI3mfxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idDYBLwpMCcd",
        "colab_type": "text"
      },
      "source": [
        "Jetons un oeil au format du dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imcp6RkCndEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j14ei74MMaci",
        "colab_type": "text"
      },
      "source": [
        "## Question:\n",
        "Affichez quelques éléments de X_train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWwIOTHBn2xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,5))\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc1f5iA1NoES",
        "colab_type": "text"
      },
      "source": [
        "Avant de pouvoir entrainer notre futur réseau nous devons faire un peu de preprocessing sur nos données en les redimensionant et en les normalisant.  \n",
        "Actuellement les données sont stockées dans un tenseur de shape (6000, 28, 28) de type uint8 avec des valeurs comprises entre [0, 255]. Nous devons les transformer en float32 dans un tenseur de taille (6000, 28*28) avec des valeurs comprises entre [0 et 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-2c-NPmoKfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHTtYhSMP65D",
        "colab_type": "text"
      },
      "source": [
        "Les labels attendus par Keras dans des problèmes de classification doivent être forme de one-hot vectors.  \n",
        "Par exemple le label 2 doit être représenter par le vecteur [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]. Nous devons convertir les labels $y$ sous cette forme avant de pouvoir les utiliser sous Keras.  \n",
        "Keras possède une méthode permettant de faire cette convertion simplement:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaq0qD4soVdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Old version: {y_train[0]}')\n",
        "\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(f'One-hot encoded version: {y_train[0]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqE7s_tVRX4g",
        "colab_type": "text"
      },
      "source": [
        "La façon la plus simple de construire un réseau sous Keras est d'utiliser les models \"Sequential\".  \n",
        "Il suffit d'instancier un de ces models et d'y ajouter les couches dont on a besoin une par une."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpX01KiBVrgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "# Nous rajoutons ici une première couche cachée de 512 neurones avec fonction d'acctivation ReLU\n",
        "# Seul la première couche à besoin de savoir la taille de ses inputs\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "# La dernière couche de notre réseau possède un appel à la fonction softmax.\n",
        "# Cela permet de produire une distribution de probabilités sur les différentes calsses possible en sortie du réseau\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# la methode summary permet de visualiser rapidement les informations du réseau\n",
        "# regardez le nombre de paramètres utilisés\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oNeUp5GT0Sk",
        "colab_type": "text"
      },
      "source": [
        "Keras possède aussi des outils permettant de visualiser l'architecture des réseaux"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHPiHluIo9Ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='mlp_model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRkObA9JTRp8",
        "colab_type": "text"
      },
      "source": [
        "Avant de pouvoir entrainer le réseau nous devons configurer son processus d’apprentissage avec .compile() afin de lui fournir la fonction de perte qu'il cherchera à minimiser et l'optimiseur qu'il pourra utiliser pour cela.  \n",
        "Enfin nous pouvons lui donner des metrics qui nous permettrons de l'évaluer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5cHdPFoopSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-CbtKrTT_Ee",
        "colab_type": "text"
      },
      "source": [
        "Le code suivant permet de lancer un apprentissage de 20 epochs sur de batchs de taille 128 et de stocker les statistiques de l'apprentissage dans un objet history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkfod6-UotUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA7L3b50VZ6e",
        "colab_type": "text"
      },
      "source": [
        "La méthode évaluate permet de voir les résulats de l'apprentissage sur le jeu de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "simwHclepFxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghue7GDxVOw8",
        "colab_type": "text"
      },
      "source": [
        "Nous pouvons afficher les courbes d'apprentissages grace aux statistiques conservées dans history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmlpxTaOWAxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_learning_curves(history):\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Plot training & validation loss values\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5MFICDUpEKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_learning_curves(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKm8-ABiXls_",
        "colab_type": "text"
      },
      "source": [
        "## Question:\n",
        "Au vu des courbes nous avons clairement overfité sur nos données d'apprentissage.  \n",
        "Vous avez vu en cours une méthode simple permettant de réduire le sur-apprentissage il s'agit du [dropout](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf). Cette methode est très simple à mettre en oeuvre dans Keras. \n",
        "Construisez un nouveau model ayant la même architecture mais incluant du dropout `model.add(Dopout(rate))`et affichez les statistques de sont apprentissage. Que constatez vous?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbapo28RnTb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "...\n",
        "model.summary()\n",
        "\n",
        "model.compile(...)\n",
        "\n",
        "history = model.fit(...)\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2McuZV3Nl2oo",
        "colab_type": "text"
      },
      "source": [
        "Vous pouvez facilement enregistrer les poids de votre model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80vFGw9KyX7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'MNIST_MLP_Keras.h5'\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRZA5Zcjpssf",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh7ZTKodkX7A",
        "colab_type": "text"
      },
      "source": [
        "![](https://miro.medium.com/max/395/1*1VJDP6qDY9-ExTuQVEOlVg.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6W9ivRsZVMF",
        "colab_type": "text"
      },
      "source": [
        "Nous allons maintenant implémenter les réseaux convolutionels que vous avez vu en cours. Ces réseaux sont capables de travailler directement avec des images en entrées.  \n",
        "Important cependant, dans Keras les réseaux convolutionels prennent en entrées des tensors de la forme suivante (image_height, image_width, image_channels) (sans inclure la dimension du batch). Les images MNIST étant en noir et blanc elles ne possèdent qu'un seul canal. Nous allons donc redimensionner nos images pour qu'elles aient la taille suivante: (28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayec6nbjqi9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Keras attend un input de la forme [taille du batch, hauteur, largeur, nb_cannaux]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6dwFqwSbKE9",
        "colab_type": "text"
      },
      "source": [
        "Nous travaillons donc directement avec des images  28x28x1.  \n",
        "Voici un exemple simple de réseau convolutionnel sous Keras.  \n",
        "Ce réseau est constitué de plusieurs couches convolutionnelles `Conv2D`.\n",
        "Chacune de ces couches possède des arguments, entre autres:\n",
        "- `filters`: le nombre de filtres en sortie de la couche de convolution\n",
        "- `kernel`: la taille des filtres de convolution\n",
        "- `activation`: la fonction d'activation appliquée sur la couche\n",
        "- `input_shape` la taille des entrées de la couche. Cet argument est uniquement nécéssaire sur la première couche les suivants calculeront automatiquement la taille de leurs entrée.  \n",
        "La documentation complète de ces couches peut êêtre trouvée [ici](https://keras.io/layers/convolutional/).  \n",
        "Le modèle possède aussi des couches `MaxPooling2D` réalisant les oppération de pooling une couche `Flatten` permettant d'applatir les matrices en sortie sous forme de vecteurs et des couches `Denses` que nous avons déjà utilisées."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHqIl-Q4pieH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9LvwhxEgvHh",
        "colab_type": "text"
      },
      "source": [
        "## Question\n",
        "Comparez le nombre de paramètres du réseau avec le précédent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "takxGMwNgz4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbj1XrSViiJ0",
        "colab_type": "text"
      },
      "source": [
        "## Question:\n",
        "Entrainez le réseaux sur X_train et affichez les courbes d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26kpRBttrWaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 12\n",
        "\n",
        "...\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUsHNWr9i4T-",
        "colab_type": "text"
      },
      "source": [
        "## Question:\n",
        "Affichez les scores sur X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9R6UMfFsjpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Test loss:', ...)\n",
        "print('Test accuracy:', ...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s253XpKDtPX_",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDun_CwxnFa7",
        "colab_type": "text"
      },
      "source": [
        "Nous allons cette fois-ci utiliser un CNN pour classifier des images en couleur.  \n",
        "Nous allons utiliser le dataset CIFAR-10 constitué de 60 000 images, en couleur, de résolution 32*32.  \n",
        "Le dataset est séparé en 2 parties, les données d’apprentissage (50 000 images) et les données de test (10 000 images).  \n",
        "La tâche consiste à classifier les images du dataset parmis 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MNMPuV1t51N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "num_train, img_channels, img_rows, img_cols =  X_train.shape\n",
        "num_classes = len(np.unique(y_train))\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BebgNXunwXW",
        "colab_type": "text"
      },
      "source": [
        "Voici un exemple d'image de chaque classe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0TsXouduZzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "for i in range(num_classes):\n",
        "    plt.subplot(2, 5, 1 + i)\n",
        "    #get first exmple of ith class\n",
        "    idx = np.where(y_train[:]==i)[0][0]\n",
        "    image = X_train[idx,::]\n",
        "    plt.imshow(image)\n",
        "    plt.title(class_names[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaBIwKogoQL1",
        "colab_type": "text"
      },
      "source": [
        "## Question:\n",
        "Similarement à ce ce que l'on a fait précédement avec le dataset MNIST, implémentez un resau CNN capable de catégoriser les images de CIFAR10.  \n",
        "N'oubliez pas la préprocessing des données et des labels.  \n",
        "Voici un exemple d'architecture mais n'hésitez pas à tester les votres.\n",
        "\n",
        "* Conv2D: filter: 32, Kernel(3,3), padding='same', activation:relu  \n",
        "* Conv2D: filter: 32, Kernel(3,3), padding='same', activation:relu\n",
        "* MaxPooling2D: (2,2)\n",
        "* Conv2D: filter: 64, Kernel(3,3), padding='same', activation:relu  \n",
        "* Conv2D: filter: 64, Kernel(3,3), padding='same', activation:relu\n",
        "* MaxPooling2D: (2,2)\n",
        "* Flatten\n",
        "* Dense 512 activation:ReLU\n",
        "* Dense num_classes activation:softamx\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPMYrGWqr-Ik",
        "colab_type": "text"
      },
      "source": [
        "## Questions\n",
        "Entrainez votre réseau et affichez vos courbes d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7F-rtz5xCVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "history = ...\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffjDTWwehO_J",
        "colab_type": "text"
      },
      "source": [
        "# Tiny Imagenet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMFWmZ63t2Vv",
        "colab_type": "text"
      },
      "source": [
        "Nous allons maintenant nous entrainer sur des images de plus grandes résolutions.  \n",
        "Pour cela nous utiliserons un sous-échantillon du célèbre dataset [Imagenet](http://www.image-net.org/challenges/LSVRC/2014/), et nous nous concentrerons sur 3 classes.  \n",
        "Commençons par télécharger les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgP1Zu2fGPG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!unzip imagenette2.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A-7RKTChXiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar zxvf imagenette2.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkqGrMpJvFgz",
        "colab_type": "text"
      },
      "source": [
        "Afin de ne pas charger les données en RAM le code suivant utilise un générateur permettant de charger les images dans la RAM uniquement lorsque l'on en a besoin.  \n",
        "Les images sont stockées dans le dossier imagenette2, lui mêême séparé en deux dossier train et val.  \n",
        "Chacun d'eux contient 10 sous dossiers: un pour chaque classe.  \n",
        "Il s'agit de l'arborescence attendue par les generateurs en Keras\n",
        "Deux générateurs sont définis un pour l'apprentissage un autre pour la validation.  \n",
        "Le préprocessing des images est géré par les générateurs regardez attentivement comment dans le code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUKorS0iP0Nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_dir = 'imagenette2'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwTu-o1cv2ev",
        "colab_type": "text"
      },
      "source": [
        "Voici un exemple d'image de chaque classe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD5AXQ3S7h3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,3,1)\n",
        "img = load_img(os.path.join(train_dir, 'n01440764/ILSVRC2012_val_00000293.JPEG'))\n",
        "plt.imshow(img)\n",
        "plt.subplot(1,3,2)\n",
        "img = load_img(os.path.join(train_dir, 'n02102040/n02102040_2474.JPEG'))\n",
        "plt.imshow(img)\n",
        "plt.subplot(1,3,3)\n",
        "img = load_img(os.path.join(train_dir, 'n02979186/n02979186_14378.JPEG'))\n",
        "plt.imshow(img)\n",
        "plt.axis('off');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swpiXg15wN0i",
        "colab_type": "text"
      },
      "source": [
        "## Question:\n",
        "Essayez d'apprendre sur ce jeu de données avec une architecture similaire à votre ancien modèle et affichez les courbes d'apprentissage.  \n",
        "Pensez à modifier la taille des inputs de la première couche et le nombre de classes en sortie.  \n",
        "Voici un exemple de code permettant de fiter votre modèle depuis un générateur:  \n",
        "```python\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=128,\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz0L31WzPNBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "\n",
        "history = ...\n",
        "\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt_pOMz3Wi8a",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vE3SK9JGteP",
        "colab_type": "text"
      },
      "source": [
        "Il est fort probable que vous ayez overfitté avec le modèle précédent.  \n",
        "Nous allons voir dans cette section une des techniques souvent utilisées en computer vision pour améliorer la qualité des modèles et diminuer l'overfiting est la data-augmentation.   \n",
        "L'idée est très simple: on applique des perturbations (rotations, zoom, ...) aux images déjà présentes dans le dataset afin de constituer de nouveaux échantillons d'apprentissage et ainsi robustifier notre modèle.  \n",
        "Le code suivant définit un générateur qui génèrera à la volée les images perturbées."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiPpzkMqVday",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "augmenting_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40, # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.2, # randomly shift images horizontally (fraction of total height)\n",
        "    height_shift_range=0.2,# randomly shift images vertically (fraction of total height)\n",
        "    shear_range=0.2,# set range for random shear\n",
        "    zoom_range=0.2,# set range for random zoom\n",
        "    horizontal_flip=True,# randomly flip images\n",
        "    fill_mode='nearest' # set mode for filling points outside the input boundaries\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rc2QtkAG5OV",
        "colab_type": "text"
      },
      "source": [
        "Voici un exemple de data-augmentation de notre générateur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS8tpqToG5ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = load_img(os.path.join(train_dir, 'n02102040/n02102040_2474.JPEG'))\n",
        "X =np.array(img)\n",
        "plt.figure(figsize=(11, 5))\n",
        "flow = augmenting_datagen.flow(X[np.newaxis, :, :, :])\n",
        "for i, X_augmented in zip(range(15), flow):\n",
        "    plt.subplot(3, 5, i + 1)\n",
        "    plt.imshow(X_augmented[0])\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFl8jWIhhI4q",
        "colab_type": "text"
      },
      "source": [
        "## Question:\n",
        "Utilisez lancer un apprentissage avec le générateur faisant de la data-augmentation sur un modèle possédant la même architecture que le modèle précédent et affichez les courbes d'apprentissage.  \n",
        "Le generateur servant pour la validation n'a pas besoin d'être augmenté.\n",
        "Que remarquez vous?\n",
        "\n",
        "### Attention la data-augmentation ralentit la vitesse d'apprentissage sour Keras traitez cette question en toute fin de scéance pour ne pas ralentir votre progréssion dans le notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33GJOgiaHBH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ...\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_generator = augmenting_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "history = ...\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aypfOEy4TNfb",
        "colab_type": "text"
      },
      "source": [
        "# Using a pre-trained convnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaqrhE0E1Tze",
        "colab_type": "text"
      },
      "source": [
        "Le réseau ne semble pas pouvoir apprendre rapidement sur le dataset.  \n",
        "Nous allons cette fois-ci utiliser une stratégie différente:\n",
        "nous allons récuperer un réseau pré-entrainé (en l'occurence sur Imagenet), couper les dérnières couches afin de récupérer les features qu'il utilise pour effectuer ses décisions. Nous utiliserons alors ces features pour entrainer un classifieur.  \n",
        "Le code suivant récupère un réseau entrainé sur Imagenet et enlève les dernières couches du réseau."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMBaf9OKIMZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(224, 224, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyNGTiF424le",
        "colab_type": "text"
      },
      "source": [
        "Il s'agit d'un modèle VGG16, voici son architecture:\n",
        "![](https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png)\n",
        "Nous récupérons dans notre cas les features en sortie de la dernière couche de pooling.  \n",
        "Nos feature sont donc de dimension $7*7*512$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVRukemxIsMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 20\n",
        "\n",
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 7, 7, 512))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = conv_base.predict(inputs_batch)\n",
        "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "        i += 1\n",
        "        if i * batch_size >= sample_count:\n",
        "            # Note that since generators yield data indefinitely in a loop,\n",
        "            # we must `break` after every image has been seen once.\n",
        "            break\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(train_dir, 2000)\n",
        "test_features, test_labels = extract_features(validation_dir, 1000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO2X6NhSs_Jj",
        "colab_type": "text"
      },
      "source": [
        "## t-SNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OvCfkpLAIiW",
        "colab_type": "text"
      },
      "source": [
        "Il peut parfois être utilie de visualiser les features afin d'avoir une indication de leur qualité.  \n",
        "Nous allons utiliser une technique de visualisation appelé t-SNE et dont voici la définition (source [Wikipedia](https://fr.wikipedia.org/wiki/Algorithme_t-SNE)):  \n",
        "\n",
        "*L'algorithme t-SNE (t-distributed stochastic neighbor embedding) est une technique de réduction de dimension pour la visualisation de données développée par Geoffrey Hinton et Laurens van der Maaten. Il s'agit d'une méthode non-linéaire permettant de représenter un ensemble de points d'un espace à grande dimension dans un espace de deux ou trois dimensions, les données peuvent ensuite être visualisées avec un nuage de points. L'algorithme t-SNE tente de trouver une configuration optimale selon un critère de théorie de l'information pour respecter les proximités entre points : deux points qui sont proches (resp. éloignés) dans l'espace d'origine devront être proches (resp. éloignés) dans l'espace de faible dimension.*\n",
        "\n",
        "*L'algorithme t-SNE se base sur une interprétation probabiliste des proximités. Une distribution de probabilité est définie sur les paires de points de l'espace d'origine de telle sorte que des points proches l'un de l'autre ont une forte probabilité d'être choisis tandis que des points éloignés ont une faible probabilité d'être sélectionnés. Une distribution de probabilité est également définie de la même manière pour l'espace de visualisation. L'algorithme t-SNE consiste à faire concorder les deux densités de probabilité, en minimisant la divergence de Kullback-Leibler entre les deux distributions par rapport à l'emplacement des points sur la carte.*\n",
        "\n",
        "Parmis les bonne pratiques il est recommandé de procéder à une PCA en amont afin de ne pas travailler dans des espaces trop grands:  \n",
        "*It is highly recommended to use another dimensionality reduction method (e.g. PCA for dense data or TruncatedSVD for sparse data) to reduce the number of dimensions to a reasonable amount (e.g. 50) if the number of features is very high. This will suppress some noise and speed up the computation of pairwise distances between samples. For more tips see Laurens van der Maaten’s FAQ.* (source [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n",
        "\n",
        "## Question\n",
        "Visulalisez vos features à l'aide des methodes [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) et [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) de scikit-learn. \n",
        "Vous reduirez dans un premier temps la dimension de vos features grace à une PCA puis utiliserez la t-SNE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJcfmgXz4QW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = np.reshape(train_features, (2000, 7 * 7 * 512))\n",
        "test_features = np.reshape(test_features, (1000, 7 * 7 * 512))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMLemhIHvrsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "X_pca = ...\n",
        "X_tsne = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9IsRmDN65r0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(16,10))\n",
        "sns.scatterplot(\n",
        "    x=X_tsne[:,0], y=X_tsne[:,1],\n",
        "    hue=train_labels,\n",
        "    palette=sns.color_palette(\"hls\", 10),\n",
        "    legend=\"full\",\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCwese6ITSWR",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfZLRD_eBk5A",
        "colab_type": "text"
      },
      "source": [
        "Nous pouvons utiliser n'importe quel classifieur pour classer nos images à partir de leur projection dans l'espace des features.\n",
        "## Question  \n",
        "Utilisez un [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) de scikit-learn pour classifier à partir des features et mesurez votre précision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJJF-ARpMGv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcXTHSQSMef9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = ...\n",
        "accuracy = accuracy_score(test_labels, y_pred)\n",
        "print(f'accuracy:{accuracy}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVy5E4MkTel7",
        "colab_type": "text"
      },
      "source": [
        "## New classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "201FhPhNC_WF",
        "colab_type": "text"
      },
      "source": [
        "Entrainez un petit réseau (une couche cachée de 256 neurones et une couche de dropout) à partir des features et mesurez sa performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkYGz9SqNyQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH1O0ZCVLqI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(\n",
        "    ...\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=2e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "...\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5SuJFVDXTs",
        "colab_type": "text"
      },
      "source": [
        "Plutôt que de créer deux modèles, un pour le calcul des features déjà entrainé et un autre pour la prise de décision, nous pouvons définir un unique modèle composé du premier et auquel on ajoute une derniere couche de classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o03bVUuKODyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu', name='features'))\n",
        "model.add(Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjpehYYUDx7r",
        "colab_type": "text"
      },
      "source": [
        "Nous allons geler les poids des couches calculant les features afin de ne pas tout ré-apprendre et d'accélérer l'entrainement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KvS-eeTQWNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Voici le nombre de couches \"trainable\":', len(model.trainable_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB0Ny84QTwo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-txN1KqT1yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Voici le nombre de couches \"trainable\" après avoir gelé le model de base:', len(model.trainable_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z_QAMLyca4C",
        "colab_type": "text"
      },
      "source": [
        "## Question:\n",
        "Entrainez le modèle et affichez sa courbe d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9hTrcA3T3qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz9ynB39Gols",
        "colab_type": "text"
      },
      "source": [
        "## Fine Tunning\n",
        "Il est possible d'ameliorer encore un peu la qualité des prédictions en effecuant ce que l'on appèle du fine tunning.  \n",
        "Le principe est très simple, nous allons dégeler les dernières couches de notre modèle de base et les entrainer conjointement avec les couches que nous lui avons ajoutées. L'idée ici est d'ajuster un peu (on utilise un learning rate plus petit que précédement) les représentations abstraites des dernières couches calculant les features pour les rendre plus pertinentes pour notre problème.  \n",
        "Dans notre cas nos features ont été apprises sur le même dataset Imagenet. Elles sont donc déjà suffisement pertinentes pour la tâche que l'on cherche à résoudre et l'on ne devrait pas forcément observer d'améliorations.  \n",
        "Voici cependant un exemple de code permettant de réaliser du fine-tuning:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3ODBW02FUiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bov1IsuHfp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = False\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name in ['block5_conv1', 'block5_conv2', 'block5_conv3'] :\n",
        "        layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ15NGzqIQBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=1e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=128,\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7puqJdvJNTF",
        "colab_type": "text"
      },
      "source": [
        "## Question:\n",
        "Nous sommes ici en présence d'un overfitting essayez de le réduire.\n",
        "Vous pouvez essayer cette fois-ci une autre méthode permettant de le reduire: la [batch normalisation](https://keras.io/layers/normalization/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCCOIRCIUBch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}